# Dockerfile.spark — Spark + Hadoop client + Java runtime
FROM ubuntu:22.04

ENV DEBIAN_FRONTEND=noninteractive

# 1) Java
RUN apt-get update && apt-get install -y --no-install-recommends \
    curl ca-certificates bash tini openssh-client \
    openjdk-11-jre-headless \
    && rm -rf /var/lib/apt/lists/*

ENV JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64
ENV PATH="$JAVA_HOME/bin:$PATH"

# 2) Hadoop client dirs (reuse your mounted /opt/hadoop-3.3.6 from compose)
#    Nothing to install here—just make sure PATH can see hdfs if needed
ENV HADOOP_HOME=/opt/hadoop-3.3.6
ENV HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop
ENV PATH="$HADOOP_HOME/bin:$PATH"

# 3) Spark (built for Hadoop 3)
ARG SPARK_VERSION=3.5.1
ARG SPARK_TGZ="spark-${SPARK_VERSION}-bin-hadoop3.tgz"
ARG SPARK_URL="https://archive.apache.org/dist/spark/spark-${SPARK_VERSION}/${SPARK_TGZ}"

RUN curl -fsSL "$SPARK_URL" -o "/tmp/${SPARK_TGZ}" \
    && tar -xzf "/tmp/${SPARK_TGZ}" -C /opt \
    && ln -s "/opt/spark-${SPARK_VERSION}-bin-hadoop3" /opt/spark \
    && rm "/tmp/${SPARK_TGZ}"

ENV SPARK_HOME=/opt/spark
ENV PATH="$SPARK_HOME/bin:$SPARK_HOME/sbin:$PATH"

# 4) A non-root working dir
WORKDIR /work